# Configuration file for code-digest
# This file defines default settings and can be overridden by CLI arguments

[defaults]
# Maximum number of tokens to include in the output
max_tokens = 150000

# Show progress indicators during processing
progress = true

# Enable verbose logging
verbose = false

# Suppress non-error output
quiet = false

[ignore]
# Additional patterns to ignore (beyond .gitignore)
patterns = [
    "*.log",
    "*.tmp",
    "*.cache",
    ".git/",
]

# Whether to use .gitignore files
use_gitignore = true

# File priorities for token-limited output
# Higher weights are included first
[[priorities]]
pattern = "**/*.rs"
weight = 100

[[priorities]]
pattern = "**/*.py"
weight = 95

[[priorities]]
pattern = "**/*.ts"
weight = 90

[[priorities]]
pattern = "**/*.js"
weight = 85

[[priorities]]
pattern = "**/*.go"
weight = 90

[[priorities]]
pattern = "**/Cargo.toml"
weight = 80

[[priorities]]
pattern = "**/package.json"
weight = 80

[[priorities]]
pattern = "**/*.md"
weight = 70

[[priorities]]
pattern = "**/*.yaml"
weight = 60

[[priorities]]
pattern = "**/*.yml"
weight = 60

[[priorities]]
pattern = "**/*.toml"
weight = 60

[[priorities]]
pattern = "tests/**"
weight = 40

[[priorities]]
pattern = "examples/**"
weight = 30

[output]
# Include directory tree at the beginning
include_tree = true

# Add syntax highlighting hints to code blocks
syntax_highlighting = true

# Maximum line length for wrapping (0 = no wrapping)
max_line_length = 0

# Template for file headers (can use {path} placeholder)
file_header_template = "## File: {path}"

[performance]
# Number of threads for parallel processing (0 = auto)
threads = 0

# Maximum file size to process (in bytes)
max_file_size = 10485760  # 10MB

# Chunk size for reading large files
chunk_size = 65536  # 64KB

[tokenizer]
# Model to use for token counting
# Options: "cl100k_base" (GPT-3.5/4), "p50k_base", "r50k_base"
model = "cl100k_base"

# Cache token counts for performance
cache_enabled = true